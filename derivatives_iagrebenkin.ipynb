{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Ilya Grebnekin\"\n",
    "COLLABORATORS = \"-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "92b4111b53cb130ec6f55a213ab1420b",
     "grade": false,
     "grade_id": "cell-2991ac3306ed22f1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Derivatives: Finite difference schemes\n",
    "\n",
    "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$ (e.g., use a central difference scheme). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "05ba834a506bc2bdff233338e05ecaeb",
     "grade": false,
     "grade_id": "cell-fe8ff43afb9d6f9e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def deriv(f, x, h):\n",
    "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
    "    \n",
    "    Compute the derivative using the symmetric scheme.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    f : callable\n",
    "        The function to differentiate\n",
    "    x : float\n",
    "        The point to compute the derivative at.\n",
    "    h : float\n",
    "        The step size for the finite different rule.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    fder : derivative of f(x) at point x using the step size h.\n",
    "    \"\"\"\n",
    "\n",
    "    fder = (f(x + h) - f(x - h)) / (2 * h)\n",
    "\n",
    "    return fder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "868c0d4fd6e922759de6fef218a0073a",
     "grade": false,
     "grade_id": "cell-8c875bcb3716d46a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Are your results consistent with the expected value of $f'(x) = 0$? Are they consistent with the expected scaling of the error with $h\\to 0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 --  0.0001\n",
      "0.001000 --   1e-06\n",
      "0.000100 --   1e-08\n",
      "0.000010 --   1e-10\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    err = deriv(lambda x: x ** 3, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, err))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "970aa7f56384426515369d5f24879a54",
     "grade": true,
     "grade_id": "cell-a354789175e34099",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "assert_allclose(deriv(lambda x: x ** 3, 0, h=1e-4),\n",
    "                0, atol=1e-6)\n",
    "assert_allclose(deriv(lambda x: x ** 4, 1, h=1e-7),\n",
    "                4, atol=1e-6)\n",
    "\n",
    "from math import log\n",
    "\n",
    "assert_allclose(deriv(lambda x: x ** 2 * log(x), 1, h=1e-5),\n",
    "                1, atol=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0534b94b3293b796ea75b12103d43c80",
     "grade": false,
     "grade_id": "cell-e758b52273b165d6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## One-sided finite difference schemes\n",
    "\n",
    "Now implement two one-sided finite difference schemes for the first derivative: a two-point forward difference and a three-point forward difference. \n",
    "\n",
    "Test your functions on $f(x) = x^2 \\log{x}$ at $x = 1$.\n",
    "Study the dependence of the error with $h$. Roughly estimate the value of the step size $h$ where the error stops decreasing.  While the error still decreses with $h$, what is the scaling of the error, is it $O(h)$ or $O(h^2)$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "37cc5e7a851b22ce66e739e9ba40c87b",
     "grade": false,
     "grade_id": "cell-1c8538ef1201bf0d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "\n",
    "def func(x):\n",
    "    return x ** 2 * log(x)\n",
    "\n",
    "\n",
    "def deriv_forward_2pt(f, x, h):\n",
    "    \"\"\"Estimate $df/dx$ at x using a two-point forward difference scheme.\"\"\"\n",
    "\n",
    "    fder = (f(x + h) - f(x)) / h\n",
    "\n",
    "    return fder\n",
    "\n",
    "\n",
    "def deriv_forward_3pt(f, x, h):\n",
    "    \"\"\"Estimate $df/dx$ at x using a three-point forward difference scheme.\"\"\"\n",
    "\n",
    "    fder = (-3 * f(x) + 4 * f(x + h) - f(x + 2 * h)) / (2 * h)\n",
    "\n",
    "    return fder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "54dc9abfc79c856e1f8ed52182b42d5b",
     "grade": true,
     "grade_id": "cell-20caa31e59ef1abf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test your functions\n",
    "\n",
    "assert_allclose(deriv_forward_2pt(func, 1, h=1e-5),\n",
    "                1, atol=1e-4)\n",
    "\n",
    "assert_allclose(deriv_forward_3pt(func, 1, h=1e-5),\n",
    "                1, atol=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for deriv3 i = 12 h = 4.018775720164609e-06\n",
      "for deriv2 i = 31 h = 3.492943259127733e-08\n"
     ]
    }
   ],
   "source": [
    "# deriv_forward_2pt consistent with the O(h) and deriv_forward_3pt consistent with the O(h^2) scaling of the error\n",
    "\n",
    "c3, c2 = 0, 0\n",
    "h = 1\n",
    "for i in range(1, 100):\n",
    "\n",
    "    h_i = h / i ** 5\n",
    "    h_1 = h / (i + 1) ** 5\n",
    "    h_2 = h / (i + 2) ** 5\n",
    "\n",
    "    if abs(deriv_forward_2pt(func, 1, h_2) - deriv_forward_2pt(func, 1, h_1)) > abs(\n",
    "            deriv_forward_2pt(func, 1, h_1) - deriv_forward_2pt(func, 1, h_i)) and c2 == 0:\n",
    "        print('for deriv2 i =', i + 1, 'h =', h_1)\n",
    "        c2 = 1\n",
    "\n",
    "    if abs(deriv_forward_3pt(func, 1, h_2) - deriv_forward_3pt(func, 1, h_1)) > abs(\n",
    "            deriv_forward_3pt(func, 1, h_1) - deriv_forward_3pt(func, 1, h_i)) and c3 == 0:\n",
    "        print('for deriv3 i =', i + 1, 'h =', h_1)\n",
    "        c3 = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d9f2b6eebab761868a4e03e52cd2331c",
     "grade": false,
     "grade_id": "cell-9e9970c151470209",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### One-sided differences at a boundary\n",
    "\n",
    "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7085535ca48ab0ad8f696e84cd2f547f",
     "grade": false,
     "grade_id": "cell-434bd93cda932f09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010000 -- -0.01386\n",
      "0.001000 -- -0.001386\n",
      "0.000100 -- -0.0001386\n",
      "0.000010 -- -1.386e-05\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x == 0:\n",
    "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
    "        return 0.0\n",
    "    else:\n",
    "        return x ** 2 * log(x)\n",
    "\n",
    "\n",
    "x = 0\n",
    "for h in [1e-2, 1e-3, 1e-4, 1e-5]:\n",
    "    der = deriv_forward_3pt(f, x, h)\n",
    "    print(\"%5f -- %7.4g\" % (h, der))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2849f470201485ccddb6f208ddee2dd4",
     "grade": true,
     "grade_id": "cell-563e73a74f102659",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert_allclose(deriv_forward_3pt(f, 0, h=1e-5),\n",
    "                0, atol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}